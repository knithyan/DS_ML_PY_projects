## Classifying Yelp Reviews into 1 star or 5 star categories based off the text content in the reviews.


## We will use the Yelp Review Data Set from Kaggle.
## Each observation in this dataset is a review of a particular business by a particular user.
## The "stars" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.
 
## The "cool" column is the number of "cool" votes this review received from other Yelp users.

## All reviews start with 0 "cool" votes, and there is no limit to how many "cool" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.

## Import libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

## Import data

yelp = pd.read_csv('yelp.csv')

## Peek at the data

yelp.info()
yelp.describe()
yelp.head()


## Exploratory Data Analysis

## create a grid of 5 histograms of text length based off of the star ratings. Reference the seaborn documentation for hints on this

g = sns.FacetGrid(yelp,col='stars')
g.map(plt.hist,'text length')

## Create a boxplot of text length for each star category.
sns.boxplot(x='stars',y='text length',data=yelp,palette='rainbow')

## Create a countplot of the number of occurrences for each type of star rating.
sns.countplot(x='stars',data=yelp,palette='rainbow')

## Groupby to get mean values of columns
stars = yelp.groupby('stars').mean()
stars.corr()

sns.heatmap(stars.corr(),cmap='coolwarm',annot=True)

## NLP CLASSIFICATION

##Create a dataframe called yelp_class that contains the columns of yelp dataframe but for only the 1 or 5 star review
yelp_class = yelp[(yelp.stars==1) | (yelp.stars==5)]

X = yelp_class['text']
y = yelp_class['stars']

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()

X = cv.fit_transform(X)

## Train Test Split

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)

from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB()

nb.fit(X_train,y_train)

predictions = nb.predict(X_test)

from sklearn.metrics import confusion_matrix,classification_report

print(confusion_matrix(y_test,predictions))
print('\n')
print(classification_report(y_test,predictions))


## USING TEXT PROCESSING

from sklearn.feature_extraction.text import  TfidfTransformer
from sklearn.pipeline import Pipeline
 ##create a pipeline with the following steps:CountVectorizer(), TfidfTransformer(),MultinomialNB()**

 pipeline = Pipeline([
    ('bow', CountVectorizer()),  # strings to token integer counts
    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores
    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier
])

##RE-do Train Test Split

X = yelp_class['text']
y = yelp_class['stars']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)

pipeline.fit(X_train,y_train)

predictions = pipeline.predict(X_test)

print(confusion_matrix(y_test,predictions))
print(classification_report(y_test,predictions))
